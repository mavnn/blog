#+TITLE: Mavnn's blog

* Types et al as accessibility tools for the ADHD brain
:PROPERTIES:
:RSS_PERMALINK: 2024/05/17/adhd_refs.html
:PUBDATE: 2024-05-17
:ID:       E4BDBC4D-9B45-448B-8F07-3ED5759A6748
:END:
I ended up with a fair number of references for my talks at Software You Can Love and LambdaDays 2024 on how I use various tools and techniques to compensate for my late diagnosed ADHD.

I'll update the page with links to recordings of the talks once they exist (the two versions will share slides but have slightly different focus on where I spend the time).

Now, the list of links!

** About ADHD
:PROPERTIES:
:ID:       216A9053-161E-4D32-856D-1ADA33CAD7D9
:END:

"How to ADHD" has lots of material on what ADHD is, how it manifests, and what you can do about it: https://howtoadhd.com/

A paper reviewing research on working memory in adults with ADHD: https://psycnet.apa.org/record/2013-16996-001

Mads Torgersen (lead designer of C# at Microsoft) talks about his own diagnosis on the No Dogma Podcast: https://nodogmapodcast.bryanhogan.net/165-mads-torgersen-adhd/

(Bonus extra: that last link has /more/ links to more ADHD resources)

Finally, I mentioned at one point an organization tool that happens to mesh fairly well with my own variant of ADHD called SkedPal: https://skedpal.com/. You prioritize tasks in advance, and assign them to "time maps" (i.e. this times are work times, these times are home times). Then you hit the button and it suggests a calendar of tasks. I've found it useful because it allows things like "this task is important to me but it doesn't matter when it is done" and "this task isn't very important but if I'm going to do it, it needs happen by Friday" and it will suggest a sane next thing to do. And when you (inevitably) fail to actually follow the plan, you just hit the button again and it suggests a new plan based on the things you actually did rather than the things it thought you were going to do. Caveat: it's not free software, and it does charge a monthly fee.

** Evidence (or not) of my favourite programming techniques being better
:PROPERTIES:
:ID:       80269C63-1F73-427F-84E9-8894E2F92795
:END:

Dan Luu's tour de force review of research into whether or not strong typing leads to more reliable code: https://danluu.com/empirical-pl/

Brian Marick has a well thought out post on why he's not fully convinced by property based testing: https://www.crustofcode.com/a-reluctant-rebuttal/. Most importantly he links to a paper written in /1990/ that partition testing has some issues, all of which would also apply to property based testing: https://www.site.uottawa.ca/~gvj/papers/Software%20Engineering%20IEEE%20Transactions%20on%201990%20Hamlet.pdf. It is worth noting that both Marick (about PBT), and Hamlet and Taylor (about partition testing) do state that they see use cases for these testing methods, but that they do also have concerns.

The arguments I've heard against domain driven design have tended to be more anecdotal but mostly boil down to: "you're making the code harder to understand by forcing developers to understand both the code /and/ the specialist terminology of the users at the same time."

** Going deeper on Property Based Testing
:PROPERTIES:
:ID:       52244290-BD09-40AE-B90A-D5F32C06CB79
:END:

I happen to be a fan of Scott Wlaschin's video and blog posts at https://fsharpforfunandprofit.com/pbt/ titled "The lazy programmer's guide to writing 1000's of tests".

Otherwise, a quick google search for "John Hughes" will net you many talks from the author of the first property based testing framework.

Fuzz testing is a related topic which somewhat overlaps, but with a different focus.

** Leaning into union types, and domain driven design
:PROPERTIES:
:ID:       FBE319BA-D61F-4B76-83D0-31922B7234AD
:END:

I cannot over stress how amazing a book "Domain Modeling Made Functional" is (again, by Scott Wlaschin) https://pragprog.com/titles/swdddf/domain-modeling-made-functional/. There is also a talk covering the basics available at https://www.youtube.com/watch?v=MlPQ0FsPxPY.

** Pushing the boundaries on types
:PROPERTIES:
:ID:       00FCAD13-75AB-4DE0-9E9B-50BF536863CA
:END:

Probably the place to start is the Idris programming language https://www.idris-lang.org/
* With style: Dev Journal 6
:PROPERTIES:
:RSS_PERMALINK: 2024/03/19/dev_journal_6.html
:PUBDATE: 2024-03-19
:ID:       A6AF23E5-C3D3-48E3-B1BF-15A90E91D4B9
:END:
#+begin_quote
This post is part 6 of the "Dev Journal" series. [[file:../../../2024/01/31/dev-journal-1.org][Part 1]] contains the series index, while the [[https://gitlab.com/mavnn/caldance/-/commits/DevJournal6?ref_type=tags][DevJournal6]] tag for the CalDance project in GitLab holds the state of the repository as described here.
#+end_quote

In theory, our log in mechanism works. But in reality it looks like this:

#+caption: Two unstyled, unlabeled text boxes next to a "Submit" button
[[file:2024/03/19/before.png]]

This is the post where we give it a make over, so that it starts looking more like this...

#+caption: A snazzy looking login page
[[file:2024/03/19/after.png]]

...while also starting to build in some interactivity, usability, and feedback via HTMX.

** The good, the bad, and the ugly
:PROPERTIES:
:ID:       CE7D966B-1EF1-4A56-A302-AC4C821AE937
:END:

You may remember from [[file:../../../2024/01/31/dev-journal-1.org][part 1]] that HTMX and Falco's markup library are both tools I'm trying out for the first time. This means that while I'm happy with the /results/ I achieved in this post, I'm not all that happy with the resulting code. Yet. There will be a refactoring follow up.

Which translates to: don't take anything as an active recommendation of how to do things, but a chance to follow along as I learn a new tool.

** The logic behind our changes
:PROPERTIES:
:ID:       1DD43FF2-7122-42FC-93C2-3D672C385531
:END:

My first attempt at nice server side UI building hinges on two key ideas. 1) each domain module should be responsible for its own UI requirements and 2) the overall UI should look coherent.

This sounds like a place for a style guide, so I created a ~StyleGuide~ directory and started hacking. We ended up with four files in here, each with their own little area of responsibility.

*** Htmx
:PROPERTIES:
:ID:       A4779FB6-F004-4AED-9237-D2EFD4EB8999
:END:

The ~Htmx.fs~ file ([[https://gitlab.com/mavnn/caldance/-/merge_requests/5/diffs#e08193e43a637c573f535f953ec65131eded9044][link to the diff]]) is arguably not really part of the style guide, but it seemed the best place I had to put it.

It defines a series of HTMX related attributes that I can then add to elements in other places without worrying about misspelling them.

#+begin_src fsharp
  let post url = Attr.create "hx-post" url
  let get url = Attr.create "hx-get" url
  let target elemId = Attr.create "hx-target" elemId
  let swap details = Attr.create "hx-swap" details
  let boost = Attr.createBool "hx-boost"
  let indicator selector = Attr.create "hx-indicator" selector
#+end_src

It also provides a helper for endpoints responding to requests which may or may not be coming from HTMX. Remember that HTMX works by allowing you to respond to a request with a fragment of HTML which will then get embedded into the already loaded page, rather than requiring a full page refresh. This is great, but it means that endpoints which represent a "whole page" can end up being called in one of two ways: by HTMX wanting just the body of the page to embed, and by the browser trying to just load a URL.

It felt like the logic for branching between these scenarios was going to come up enough it was worth capturing in a named function, so I did:

#+begin_src fsharp
  let htmxOrFull branches =
    handler {
      let! headers = Request.getHeaders |> Handler.fromCtx

      let hasHxRequestHeader =
        headers.Keys.Contains "HX-Request"

      let isRequestingFullPage =
        match
          headers.TryGetBoolean "HX-History-Restore-Request"
        with
        | Some true -> true
        | Some false
        | None -> false

      if hasHxRequestHeader && (not isRequestingFullPage) then
        return! branches.onHtmx
      else
        return! branches.onFull
    }
#+end_src

We'll be seeing this again in a bit.

*** Modifier
:PROPERTIES:
:ID:       663C5440-5C89-4D43-90B8-EA4BBAF9AB6C
:END:

I'm planning on using Bulma as the basis for my CSS as it hits a reasonably sweet spot for me between having a good enough version of "most things" built in and not requiring me to mutate my HTML /too/ much to accommodate it. So the next thing to add was constants for some of the most common modifier classes that Bulma supports.

#+begin_src fsharp
  module Mavnn.CalDance.StyleGuide.Modifiers

  open Falco.Markup

  let isPrimary = Attr.class' "is-primary"

  let isLink = Attr.class' "is-link"

  let isInfo = Attr.class' "is-info"

  let isSuccess = Attr.class' "is-info"

  let isWarning = Attr.class' "is-warning"

  let isDanger = Attr.class' "is-danger"
#+end_src

Boom. Done. Compiler as a spellcheck, tick.

*** Layout
:PROPERTIES:
:ID:       2E7BD423-B21E-4092-96DC-6267E23F6058
:END:

As with the modifiers, I wanted to make it a little bit easier to do the "right thing" when creating a view, so I set up ~Layout.fs~ ([[https://gitlab.com/mavnn/caldance/-/merge_requests/5/diffs#fa9c7c3d5630a543415353918d553e91b7edc402][link to the diff]]) which includes a ~page~ function that takes a title and a list of sections and a set of broadly applicable elements like titles and links.

At the moment the page template loads all of the libraries from shared CDNs, which is something we'll want to change before going to production. We're grabbing Bulma and HTMX as you'd expect, and also the "morphing" library written by the HTMX authors which attempts to only replace elements in the DOM that have actively changed. We also add a ~meta~ element to tell HTMX that when it adds a class to an element to signify it is loading, it should use the ~is-loading~ class from Bulma rather than the ~htmx-request~ class it defaults to.

*** Form
:PROPERTIES:
:ID:       96A13037-44FB-437C-B895-F1B8846BA366
:END:

The ~Form.fs~ module ([[https://gitlab.com/mavnn/caldance/-/merge_requests/5/diffs#26465d4af42079e4d5f2d9c698268260af59e9a0][link to the diff]]) is the place where I feel I've probably over engineered things. I started putting together a set of builder helpers and types for building forms and... yeah. I don't know. I think it's probably ended up a case of trying to add the abstraction before building the second use of something, and it shows. I'm not all that happy with the code that results.

I'm not going to go into too much detail on this one, I'm just going to show it in use and remind the reader that this API may change in the future.

** Actually doing the thing
:PROPERTIES:
:ID:       7ABF4019-16C8-4CAD-8EAA-5DFBE302D63D
:END:

With our helpers constructed, we can start using them. Simple full page endpoints are quite simple; we just swap in the new ~Layout~ functions and we're good to go. For example, the view for the home page now looks like this:

#+begin_src fsharp
  Layout.page
    "Home"
    [ Layout.containerSection
        [ Layout.title
            Layout.T1
            (match user with
              | Some u -> $"Hi {u.username}!"
              | None -> "You should go log in!")
          Layout.paragraphX
            []
            [ Text.raw "Would you like to "
              Layout.link
                (greeting.greetingLink "Bob")
                "greet Bob?" ] ] ]
#+end_src

As soon as we get to adding things like navigation bars to the page template they will all just appear.

The magic, again, begins in the ~User.fs~ module. Let's have a think about the request life cycle with HTMX.

*** Option 1: the user GETS the log in (or sign up) page
:PROPERTIES:
:ID:       D0D5470E-9543-41B2-8934-50460A2A169A
:END:

In this case, we want to send a full page back to the user with an empty "user details" form; this form should not show any validation errors (don't you hate it when a form tells you empty fields aren't allowed before you've started typing?!).

*** Option 2: the user POSTS invalid user data
:PROPERTIES:
:ID:       C51561BA-0DCC-4BAE-87E3-DB3C1AE1D298
:END:

Well, if the form fields just aren't in the POST we should return a 400: something is just broken. But if the correct fields exist and this request is flagged as being made by HTMX, what we want to do is update the form with the information about what the user needs to change. Preferably without removing all the information they've already added!

*** Option 3: the user POSTS valid user data
:PROPERTIES:
:ID:       740548F8-EF9B-4E17-B4F0-145970D81463
:END:

In this case we want to log the user in and navigate them somewhere else in the website. We don't just want to return the form, we want to return the special ~HX-Location~ header which tells HTMX "load the body of that location and substitute it in to avoid a full page reload".

In the case where we return an updated form, it is critical that as closely as possible it has exactly the same HTML structure as before to allow the merge logic to do its thing, so to allow that I built a "user data form" builder function that does all the things we need it to.

It's a bit of a monster, but let's have a look:

#+begin_src fsharp
  let private userForm
    csrfToken
    location
    usernameValue
    usernameProb
    passwordValue
    passwordProb
    =
    let userInput =
      Form.InputConfig.make "text" "username" "Your username"
      |> Form.InputConfig.addLabel "Username"
      |> Form.InputConfig.addIcons (Form.Left "mdi-account")
      |> Form.InputConfig.setValue usernameValue
      |> fun ic ->
          match usernameProb with
          | Some prob -> Form.InputConfig.addError prob ic
          | None -> ic
      |> Form.input

    let passwordInput =
      Form.InputConfig.make
        "password"
        "password"
        "Your password"
      |> Form.InputConfig.addLabel "Password"
      |> Form.InputConfig.addIcons (Form.Left "mdi-lock")
      |> Form.InputConfig.setValue passwordValue
      |> fun ic ->
          match passwordProb with
          | Some prob -> Form.InputConfig.addError prob ic
          | None -> ic
      |> Form.input

    Form.form
      { csrfToken = csrfToken
        id = "userform"
        modifiers =
          [ Htmx.post location
            Htmx.target "closest form"
            Htmx.indicator "#userFormSubmit button"
            Htmx.swap "morph:{ignoreActiveValue:true}" ]
        controls =
          [ userInput
            passwordInput
            Form.button
              "userFormSubmit"
              "submit"
              "Submit"
              [ Modifiers.isPrimary ]
              "Submit" ] }
#+end_src

The start of the function builds are two input fields, and then the interactive logic is all contained within the 4 HTMX attributes towards the end. These tell HTMX that it should post the form values to the location specified, place a loading indicator on the button within the element with ID ~userFormSubmit~, and then should try and morph the HTML it gets back into the closest form element.

Now are post methods can return one of two different responses (assuming that we have form data, etc); if authentication succeeds we can send an empty 200 response with a location header and our session cookies:

#+begin_src fsharp
  let private signIn authScheme principal url =
    handler {
      do!
        Handler.fromCtxTask (fun ctx ->
          task { do! Auth.signIn authScheme principal ctx })

      return!
        Handler.fromCtx (
          Response.withHeaders [ "HX-Location", url ]
          >> ignore
        )
    }
#+end_src

If the data is invalid, we can respond with a form containing the relevant error messages, like so:

#+begin_src fsharp
  let private authenticationFailed formData location =
    let failedAuth =
      "Matching username and password not found"

    Response.ofHtmlCsrf (fun token ->
      userForm
        token
        location
        (Some formData.username)
        (Some failedAuth)
        (Some formData.password)
        (Some failedAuth))
#+end_src

Notice that we're carry through the form data that was posted to us rather than clearing the form out on every submit.

This is also the module where we start making use of the HTMX branching helper we set up above, so we can add endpoints like:

#+begin_src fsharp
  let private logoutEndpoint routeNamespace =
    Handler.toEndpoint
      get
      (logoutRoute routeNamespace)
      (fun () ->
        Htmx.htmxOrFull
          { onHtmx =
              handler {
                do! signOut "Cookies" "/"
                return Response.ofEmpty
              }
            onFull =
              handler {
                return
                  Response.signOutAndRedirect "Cookies" "/"
              } })
#+end_src

Browsing directly to the log out link in your browser will get you a redirect status code response, while clicking a ~log out~ link within the web app will take you back to the index page (logged out!) without having to do a full page refresh.

*** That's a wrap
:PROPERTIES:
:ID:       8DAC383D-CBB0-4D8F-A3FA-59AADA621516
:END:

So, that's the main changes for this post. As normal there's the link at the top of the post to the repo as it was when the post was written. I'm not totally happy with the internal results here, but I'm happy enough that I don't want to spend time refactoring it before I've started using it on a second use case.

Speaking of which, keep an eye out for the next post where we'll actually let a user /do/ something.
* Internal quality review: Dev Journal 5
:PROPERTIES:
:RSS_PERMALINK: 2024/03/09/dev_journal_5.html
:PUBDATE: 2024-03-09
:ID:       AF690C89-0889-442A-9922-2DE826285F84
:END:
#+begin_quote
This post is part 5 of the "Dev Journal" series. [[file:../../../2024/01/31/dev-journal-1.org][Part 1]] contains the series index, while the [[https://gitlab.com/mavnn/caldance/-/commits/DevJournal5?ref_type=tags][DevJournal5]] tag for the CalDance project in GitLab holds the state of the repository as described here.
#+end_quote

Refactoring. One of those terms that gets thrown around a lot by developers, but rarely gets well defined.[fn:1]

Keeping a code base reliable, easy to maintain, and fast to deliver on is hard work, and often gets confused when we start talking about writing code that is "clean" (a word many moral implications that are not appropriate here) or "good" (what does "good" mean anyway?).

Fortunately I don't need to write much to clarify your or my thinking here, because Geepaw Hill has already done an excellent job of doing so in this [[https://www.geepawhill.org/2018/01/09/underplayed-the-correlation-premise-in-depth/][2018 blog post]] where he explains the term "internal quality", which is the quality level of a code base as measured by how easy it is for /humans to change the code correctly/.

Go read the post. It's good, I'll wait. Even if (like me) you don't always practice TDD!

Once you've done that, you can come back to this post which is about our first round of "internal quality control" commits to the CalDance project now that it actually, you know, does something. /None/ of these commits alter the user experience or functionality of the code in any way.

** Commit 1: central package management
:PROPERTIES:
:ID:       0B8646A1-19AE-46E6-A4A1-EB9BCE3CEB0B
:END:

#+begin_quote
[[https://gitlab.com/mavnn/caldance/-/commit/cdef80ad7bea6414357b99060b79d9f4b2cea9cf][Commit diff]]
#+end_quote

The first commit eliminates a surprisingly common source of bugs in a project: mismatched dependency versions between what you test, and what you deploy.

To help combat this, in 2022 the NuGet introduced "[[https://devblogs.microsoft.com/nuget/introducing-central-package-management/][central package management]]" which is a mechanism to allow each of your project files to specify /which/ packages it depends on, while managing the versions of /all/ packages across your whole repository in one central location.

Given that a new major version of Marten was released recently and I wanted to upgrade to use it, it seemed an ideal moment to put in a top level ~Directory.Packages.props~ file and remove the version numbers of dependencies from our ~fsproj~ files. An entire category of bugs eliminated permanently.

The only code changes in this commit are to account for changes to how custom logging is implemented in Marten 7.0.

** Commit 2: logging improvements
:PROPERTIES:
:ID:       52FE1808-CD67-4BA5-9872-9C9DA2D9F88B
:END:

#+begin_quote
[[https://gitlab.com/mavnn/caldance/-/commit/14e38a1343566381628179e973c2b47341107a91][Commit diff]]
#+end_quote

Talking about logging, our second commit enhances the logging we added to Marten to make sure that we carry through the ~RequestId~ assigned by AspNetCore to any Marten operations. We also add an environment variable switch to change over to structured JSON logging in our packaged docker container; this is considerably more verbose but means that we always know which component is logging and which request the log relates to when we start feeding the logs through to a log aggregator in production.

** Commit 3: tests
:PROPERTIES:
:ID:       C1F07196-9C20-45B8-AA4E-B3358ECC0BAE
:END:

#+begin_quote
[[https://gitlab.com/mavnn/caldance/-/commit/7072d5c5d77128da5330ec03df303ccf15f484d8][Commit diff]]
#+end_quote

I've been lax on testing so far, and the place where that bothered me most was that I wasn't completely certain that the type safe route definition library I'd built would actually construct links that would "round trip" correctly through the AspNetCore machinery.

The idea is that I can define a route definition like so:

#+begin_src fsharp
  let private greetingRoute =
    literalSection "/greetings/" ./+ stringSection "name"
#+end_src

And using that route definition I should be able to create links to an endpoint that receives any path parameters without them being changed.

#+begin_src fsharp
  // Any path I create with this function...
  let link yourName = greetingRoute.link yourName

  // ...should get handled by this endpoint, and
  // ~greetingHandler~ should receive ~yourName~ as an input
  let greetingEndpoint =
    Handler.toEndpoint get greetingRoute greetingHandler
#+end_src

I wasn't sure how strings requiring URL escaping would be handled, so I added unit tests that actually call the underlying AspNet libraries to make sure I wasn't going to have any unpleasant surprises.

It was a good thing I did, too, because the code did in fact do the wrong thing with strings that needed escaping. So this PR also includes the fixes.

You can see the resulting test code in the new [[https://gitlab.com/mavnn/caldance/-/blob/DevJournal5/Server.Test/src/RouteDef.fs][RouteDef]] file in ~Server.Test~, which also shows just how easy it is to create a set of parameterized tests in Expecto.

** Commit 4: standardize domain module setup
:PROPERTIES:
:ID:       4AADAD4B-2084-46FC-A77D-F054ECFAEF92
:END:

#+begin_quote
[[https://gitlab.com/mavnn/caldance/-/commit/f7cec1f8109d0f50ebdc0884c01b30706c137e94][Commit diff]]
#+end_quote

In the previous post I said that I was a bit unhappy with how much of its internals the user domain module was exposing, and maybe I should give a standard way of a domain context to define itself - but it would be premature to do so with only one context.

Then I realized that in some ways I already had a couple of other contexts; the home page, which you could claim is a bit borderline to call a context, and the greetings functionality which allows you to greet somebody.

In a way this is smoke and mirrors; I'm well aware that these are not really bounded contexts within a domain in the way that we mean when talking about domain driven design. But at the same time, the point of writing this sort of "hello world" code is precisely because it starts telling you enough about the system you're building to be able to start designing based on reality rather than a set of assumptions.

Looking at the code in question, it became clear that one thing would definitely already be helpful: an interface defining what endpoints a domain context provides and what config it needed to add to Marten.

That led to the ~DomainSetup~ module:

#+begin_src fsharp
  module Mavnn.CalDance.DomainSetup

  open Falco
  open Marten

  type IConstructedContext =
    abstract member endpoints: HttpEndpoint list
    abstract member martenConfig: StoreOptions -> unit
#+end_src

A bit of rearranging later, and we now have three domain modules all which export a context class that both implements the interface above and is also a convenient place to expose any link builders that the module wants to expose. A lot of other code could then immediately become private to each module.

** Wrapping up
:PROPERTIES:
:ID:       33479AA9-6DDB-4014-93A2-952156971146
:END:

If you're an F# developer (or interested in becoming one) I hope the details of the commits are helpful. But there's a bigger take away here: names don't just matter /in/ our code; talking to people with terminology that is easy for them to grasp and which highlights the areas of shared importance on all sides is an enormously valuable skill. You may well struggle to explain why you want to spend time refactoring ("you want to spend time making changes to the routing module that /don't/ change what the code does?"), but "we need to improve the internal quality of the routing module so that we can write new features more quickly and correctly" is probably much easier to get agreement about.

I hope you're enjoying this journey of discovery with me - as always, if you have questions or comments all of the code is in the [[https://gitlab.com/mavnn/caldance][CalDance]] repository on GitLab. And if you'd like someone to help you keep the internal quality of *your* code base high then reach out about my [[file://../../../2024/01/29/short_term_help.org][short term consultancy]] services.

Next time: [[file:../../../2024/03/19/dev_journal_6.org][starting to shape up our actual user interface]].

** Footnotes
:PROPERTIES:
:ID:       97E8B026-B07D-4250-B9DD-EFC9EABCF1A6
:END:

[fn:1] Yes, yes. I know it /does/ have a good definition. I'm just saying people don't use it very often, and it is actually quite hard to succinctly explain to someone who hasn't already got the context to know why you'd want to do such a thing.
* Log in, log out: Dev Journal 4 (part 2)
:PROPERTIES:
:RSS_PERMALINK: 2024/03/05/dev_journal_4_2.html
:PUBDATE: 2024-03-05
:ID:       7009D8D4-241F-4CEF-A17B-083A1B8EAB8C
:END:
#+begin_quote
This post is the second half of a two part update in the "Dev Journal" series. [[file:../../../2024/03/01/dev_journal_4.org][The first half]] talks about adding dependencies to the project on postgresql and the Marten event store library, which we'll look at using in this post. [[file:../../../2024/01/31/dev-journal-1.org][Part 1]] contains the series index, while the [[https://gitlab.com/mavnn/caldance/-/commits/DevJournal4?ref_type=tags][DevJournal4]] tag for the CalDance project in GitLab holds the state of the repository as described here.
#+end_quote

So. We have an event store. Our website is going to have users. How do we go about user management?

** Where's the cheese?
:PROPERTIES:
:ID:       E683F727-E8EE-468E-9721-068CED332C43
:END:

To borrow a term from domain driven design, this sounds like a "bounded context" within our system. Other parts of the code may care about certain events happening related to users (users being created, that kind of thing), but they probably shouldn't know or care about how the internals of "a user" work or what it takes to authenticate a user.

There are as many ways of organizing your code as there are grains of sand on the beach, but fundamentally all of the ones that help are about choosing where to have boundaries in your code base.

We are going to have three horizontal slices; shared library code, domain logic (our "business" code), and execution environment. Vertically we're going to slice the domain logic by bounded context - of which, admittedly, we only have one at the moment.

We end up with something like (things further down the table depend on the things above):

+--------------------------------------------------+
| Http Handler abstraction, UI components          |
+-------------------+------------------------------+
| User domain logic | Things users do domain logic |
+-------------------+------------------------------+
| Read configuration files, start the web server   |
+--------------------------------------------------+

You'll notice that this doesn't group the code by the technical task the code is trying to achieve, a pattern you'll often find in example project templates where you'll end up with a "Controllers" directory and a "Views" directory. It's also not an organization along "clean/hexagon/ports and adapters" lines with a strict demarcation between code that speaks to the outside world achieved via interfaces and abstractions.

It's not that I feel that either of those patterns has no merit (although I feel like the main driver of the first pattern is that you can suggest it even for projects you /know nothing about/ which is a useful property when writing templates and dispensing nuggets of wisdom at conferences about the *one true way* to organize code). But I do feel that for the vast majority of code bases, it is a far bigger gain to productivity to be able to co-locate code by /purpose/ than by /type/.

Let's face it: while you sometimes pick up a story/card/work ticket that requires you to go and change all the controllers (normally during dependency upgrades), or replace all the database interface implementations (you're about to have a long few months), it is much more likely on a day to day basis that you're trying to add a new field to the data we store about users, and you want to update the data store, business logic, and UI of /users/ to be able to do that. Taking this logic to its logical extremes leads you towards microservices - but that starts to bring in a different type of complexity of its own.

All of this to say: there's now a folder called ~Domain~ which holds our new, shiny, user management code in a file called: /drumroll, please/ ~User.fs~. Let's have a look at it in detail.

** The cheese. We have found it.
:PROPERTIES:
:ID:       F93BB932-C241-4849-9722-350EF74D246E
:END:

#+begin_src fsharp
  module Mavnn.CalDance.Domain.User

  open Falco
  open Falco.Routing
  open Falco.Markup
  open Falco.Security
  open Marten
  open Marten.Events.Aggregation
  open Marten.Events.Projections
  open Mavnn.CalDance
  open Mavnn.CalDance.Routing
  open System.Security.Claims
  open Microsoft.AspNetCore.Identity
#+end_src

As just mentioned, this module is going to be responsible for the whole vertical slice of the application for user management, so we start by including everything we need from the data store (~Marten~) through to the UI (~Falco.Markup~). We could have created sub modules within a Users folder if needed, but the module is only ~300 lines long so I haven't split it up (yet).

#+begin_src fsharp
  type User = { id: System.Guid; username: string }

  type UserState =
    | Active
    | Disabled

  [<CLIMutable>]
  type UserRecord =
    { Id: System.Guid
      Username: string
      PasswordHash: string
      State: UserState }

  type UserEvent =
    | Created of UserRecord
    | PasswordChanged of passwordHash: string
    | Disabled
#+end_src

Next we define a few data types that represent our users, and the events that can happen to them over time. This is important because we are "event sourcing" the state of our users, meaning that the golden source of truth for what state a user is in is defined by what events have happened to them so far. The two representations of the user represent what we care about in the running system (the main ~User~ type) and what we need to store about them on disk (the ~UserRecord~ type); in general we would expect that other modules /might/ make use of the ~User~ type but in general they should not make use of the ~UserRecord~ type. Its an open question in my mind whether it should actually be marked as a private type declaration, but I've erred on the side of leaving it available for now.

A minor implementation detail: to try and keep the incremental steps of the project manageable I'm using the default (de)serializers for Marten, which require the object to be deserialized from the data base has a default constructor and mutable fields, which we get from the ~[<CLIMutable>]~ attribute. We'll probably remove that going forwards by switching to a serialization strategy that works with immutable F# records.

The life cycle of our users is very simple at the moment; a ~Created~ event signals that a new, active, user was created. That user can change their password, or they can be marked disabled which effectively ends the lifecycle of the user. There's no way to reactivate a user now, although we could always add one later.

#+begin_src fsharp
  type UserRecordProjection() =
    inherit SingleStreamProjection<UserRecord>()

    member _.Create(userEvent, metadata: Events.IEvent) =
      match userEvent with
      | Created user -> user
      | _ ->
        // We should always receive a created event
        // first so this shouldn't ever happen...
        // ...but it might, and we don't want to throw
        // in projections.
        { Id = metadata.Id
          Username = ""
          PasswordHash = ""
          State = UserState.Disabled }


    member _.Apply(userEvent, userRecord: UserRecord) =
      task {

        match userEvent with
        | Created _ ->
          // Should never occur after the first event in the stream
          // so we ignore duplicates
          return userRecord
        | PasswordChanged passwordHash ->
          match userRecord with
          | { State = UserState.Disabled } ->
            // Don't update password of disabled users
            return userRecord
          | user ->
            return
              { user with
                  PasswordHash = passwordHash }
        | Disabled ->
          match userRecord with
          | { State = UserState.Disabled } ->
            return userRecord
          | { State = Active } ->
            return
              { userRecord with
                  State = UserState.Disabled }
      }
#+end_src

~Marten~ leans heavily into the code reflection capabilities of the dotnet framework, allowing us to configure our data store in terms of the in program types we want it to store. A "projection" in event sourcing is the logic which takes a list of events (our base line source of truth) and turns it into a current state, so this class defines a projection that will create and/or update ~UserRecord~ data in Marten's document store (we know it does this because it implements the ~SingleStreamProjection<UserRecord>~ interface). It will project /from/ events of the ~UserEvent~ type, because that is the type of the first argument of the ~Create~ and ~Apply~ methods we have supplied.

There are a few conventions we need to follow here to allow for this minimalist a configuration. Our current state type /must/ have an ~Id~ (or ~id~) field of type string, uuid, or integer. And when an event matching the signature of our projection is pushed to a stream with an ID, the resulting update to the current status type must produce a document with the same ID as the stream ID.

We're treating our records as immutable objects (because we're planning to make them immutable going forward), so our create and apply methods return a ~Task<UserRecord>~; if the document type was mutable we would also have the options of mutating it in place and returning void.

With that explanation out of the way, hopefully the state machine that represents our user life cycle is clear in the code above.

Now that we can store information about our users, and update them based on what is happening to them, it's time to start implementing the actual responsibilities of the module. We're keeping things minimal to get started, so we'll implement only the three things we /really/ need: sign up, log in, and log out.

#+begin_src fsharp
  type LoginFormData = { username: string; password: string }

  let findUserRecord (username: string) =
    Marten.withMarten (fun marten ->
      marten
        .Query<UserRecord>()
        .SingleOrDefaultAsync(fun ur ->
          ur.Username = username))
    |> Handler.map Marten.returnOption

  let loginRoute = RouteDef.literalSection "/login"
  let logoutRoute = RouteDef.literalSection "/logout"
  let signupRoute = RouteDef.literalSection "/signup"

  let getSessionUser: Handler<User option> =
    Handler.fromCtx (fun ctx ->
      match ctx.User with
      | null -> None
      | principal ->
        match
          (System.Guid.TryParse(
            principal.FindFirstValue("userId")
           ),
           principal.FindFirstValue("name"))
        with
        | ((false, _), _)
        | (_, null) -> None
        | ((true, id), username) ->
          Some { id = id; username = username })
#+end_src

A few definitions and helpers start us off; what data a form needs to capture for someone to sign up/log on, what urls exist and are managed by this module, and a couple of helper functions for obtaining a user record and a user session from the current HTTP context (using the ~Handler~ type we talked about in the last post).

#+begin_src fsharp
  let loginGetEndpoint =
    Handler.toEndpoint get loginRoute (fun () ->
      Handler.return' (
        Response.ofHtmlCsrf (fun csrfToken ->
          Elem.html
            []
            [ Elem.body
                []
                [ Elem.form
                    [ Attr.method "post" ]
                    [ Elem.input [ Attr.name "username" ]
                      Elem.input [ Attr.name "password" ]
                      Xss.antiforgeryInput csrfToken
                      Elem.input
                        [ Attr.type' "submit"
                          Attr.value "Submit" ] ] ] ])
      ))
#+end_src

Our first end point is straight forward. When we receive a get request to the login path, we reply with a form containing a token to prevent cross site vulnerabilities and username and password fields.

#+begin_src fsharp
  let private makePrincipal userRecord =
    let claims =
      [ new Claim("name", userRecord.Username)
        new Claim("userId", userRecord.Id.ToString()) ]

    let identity = new ClaimsIdentity(claims, "Cookies")

    new ClaimsPrincipal(identity)

  let passwordHasher = PasswordHasher()

  let updateUser (id: System.Guid, events: seq<UserEvent>) =
    handler {
      do!
        Marten.withMarten (fun marten ->
          task {
            // explicitly assign this as an array of objects
            // so that Marten chooses the correct method
            // overload for `Append`
            let eventObjs: obj[] =
              Array.ofSeq events |> Array.map box

            marten.Events.Append(id, eventObjs) |> ignore
            return! marten.SaveChangesAsync()
          })

      return!
        Marten.withMarten (fun marten ->
          marten.LoadAsync<UserRecord>(id))
    }
#+end_src

Our next end point is going to actually handle the form coming in, so it requires a few more helpers. The web framework we're using will handle things like sessions for us, but only if we "buy into" the .NET standard ways of representing a user, in this case using the ~ClaimsPrincipal~ type - so we have a helper to map from one of our user records to a claims principal. We initialize a password hasher which will salt and hash our passwords for us (don't roll your own crypto, folks, especially when your language ecosystem has a decent implementation ready for you). And finally we add an other method that works within our HTTP context expressions - ~updateUser~ takes the ID of a user and a list of events and returns the updated ~UserRecord~.

With all of that in place, we can write the ~loginPostEndpoint~.

#+begin_src fsharp
  let loginPostEndpoint =
    Handler.toEndpoint post loginRoute (fun () ->
      handler {
        let! loginData =
          Handler.formDataOrFail
            (Response.withStatusCode 400 >> Response.ofEmpty)
            (fun f ->
              Option.map2
                (fun username password ->
                  { username = username
                    password = password })
                (f.TryGetStringNonEmpty "username")
                (f.TryGetStringNonEmpty "password"))

        let! userRecord =
          findUserRecord loginData.username
          |> Handler.ofOption (
            Response.withStatusCode 403 >> Response.ofEmpty
          )

        let verificationResult =
          passwordHasher.VerifyHashedPassword(
            userRecord,
            userRecord.PasswordHash,
            loginData.password
          )

        match verificationResult with
        | PasswordVerificationResult.Failed ->
          return
            (Response.withStatusCode 403 >> Response.ofEmpty)
        | PasswordVerificationResult.Success ->
          return
            Response.signInAndRedirect
              "Cookies"
              (makePrincipal userRecord)
              "/"
        | PasswordVerificationResult.SuccessRehashNeeded ->
          let! _ =
            updateUser (
              userRecord.Id,
              [ PasswordChanged(
                  passwordHasher.HashPassword(
                    userRecord,
                    loginData.password
                  )
                ) ]
            )

          return
            Response.signInAndRedirect
              "Cookies"
              (makePrincipal userRecord)
              "/"
        | _ ->
          return
            failwithf
              "Unknown password verification result type %O"
              verificationResult

      })
#+end_src

Time to actually use our ~handler~ expression in earnest! There is some personal preference in play here, but personally I really like the clear flow of the request we can see happening in this code. We either have the form data we need, or we return a ~400~ error. Then we either find a user record with a matching username, or we return a ~403~ error (we don't want to reveal whether a username exists or not, so we return the same code as for when the password is incorrect; security +1, helpful error messages to users -1). Then we check the password, and we either return ~403~ (if it is wrong) or log you in if it is correct. A minor piece of extra complexity is introduced by the fact that the password hasher may signal that the password is correct but the /hash/ needs updating in storage, a background operation that the user does not need to know about.

I'll leave the other end points for the reader to read at their leisure [[https://gitlab.com/mavnn/caldance/-/blob/e62126228d63e77834112a193fcb0396f4410bc5/Server/src/Domain/User.fs][on Gitlab]], as they are either trivial (~logoutEndpoint~) or very similar to the log in end points (~signupGetEndpoint~ and ~signupPostEndpoint~).

Finally, we get to the end of the module where we export everything that the web server setup code (the bottom layer in my newly christened "julienned domain sandwich" architecture).

#+begin_src fsharp
  let endpoints =
    [ loginGetEndpoint
      loginPostEndpoint
      logoutEndpoint
      signupGetEndpoint
      signupPostEndpoint ]

  let martenConfig (storeOptions: Marten.StoreOptions) =
    storeOptions.Projections.Add<UserRecordProjection>(
      ProjectionLifecycle.Inline
    )
#+end_src

At the moment, with only one domain, this is just an adhoc export of the end points we're wanting to add to the webserver and the projections we want to add to ~Marten~. As the project grows, we'll probably add an interface that each of our domain modules will export which will provide to allow a standardized process for consuming the needed configuration. But there's little point trying to proactively create an abstraction over a single example of a pattern.

And there you have it; event sourced (basic) user management for our web application. If you have thoughts and questions, drop them as an issue on the [[https://gitlab.com/mavnn/caldance/-/blob/e62126228d63e77834112a193fcb0396f4410bc5/Server/src/Domain/User.fs][CalDance repository]]. I'd love to see example repositories having in depth discussions of when the architecture they suggest is or isn't useful, even if (especially if!) that discussion includes comments critical of the architecture demonstrated.

Next up: [[file:../../../2024/03/09/dev_journal_5.org][a round of internal quality control]].
